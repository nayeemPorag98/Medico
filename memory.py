import os
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings
from sentence_transformers import SentenceTransformer
from langchain_text_splitters import RecursiveCharacterTextSplitter
from PyPDF2 import PdfReader

# -----------------------------
# â¿¡ Load environment variables
# -----------------------------
load_dotenv()

PDF_PATH = os.path.join("data", "medical_book.pdf")

print("ğŸ“¥ Step 1: Loading Medical Book PDF...")
if not os.path.exists(PDF_PATH):
    raise FileNotFoundError(f"âŒ PDF not found at: {PDF_PATH}")

reader = PdfReader(PDF_PATH)

# -----------------------------
# â¿¢ Extract text from PDF
# -----------------------------
print("ğŸ“– Extracting text from PDF...")
raw_text = ""
for page in reader.pages:
    raw_text += page.extract_text() + "\n"

print(f"âœ… Extracted {len(raw_text)} characters of text")

# -----------------------------
# â¿£ Split into chunks
# -----------------------------
print("âœ‚ Splitting text into chunks...")
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

texts = text_splitter.split_text(raw_text)
print(f"âœ… Created {len(texts)} text chunks")

# -----------------------------
# â¿¤ Embedding model wrapper
# -----------------------------
class SentenceTransformerEmbeddings(Embeddings):
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        print(f"ğŸ§  Loading embedding model â†’ {model_name}")
        self.model = SentenceTransformer(model_name)
        print("âœ… Embedding model loaded")

    def embed_documents(self, docs):
        print(f"ğŸ”„ Embedding {len(docs)} chunks...")
        return self.model.encode(
            docs,
            convert_to_numpy=True,
show_progress_bar=True
        ).tolist()

    def embed_query(self, text):
        return self.model.encode([text], convert_to_numpy=True)[0].tolist()

# -----------------------------
# â¿¥ Initialize embedding
# -----------------------------
embedding = SentenceTransformerEmbeddings()

# -----------------------------
# â¿¦ Create and save FAISS index
# -----------------------------
print("ğŸ“¦ Building FAISS vector store...")
vectorstore = FAISS.from_texts(texts, embedding=embedding)

SAVE_PATH = "faiss_medical_book"
vectorstore.save_local(SAVE_PATH)

print(f"ğŸ’¾ Saved FAISS index â†’ {SAVE_PATH}")
print("ğŸ‰ All steps completedÂ successfully!")
